import streamlit as st
import pandas as pd
import plotly.graph_objs as go
import numpy as np

st.set_page_config(page_title="Dooch XRL(F) ì„±ëŠ¥ ê³¡ì„  ë·°ì–´", layout="wide")
st.title("ğŸ“Š Dooch XRL(F) ì„±ëŠ¥ ê³¡ì„  ë·°ì–´ v3.0 (ë¶„ì„ ê¸°ëŠ¥ ê°•í™”)")

# --- ì‹ ê·œ ê¸°ëŠ¥: ìš´ì „ì  ë¶„ì„ í•¨ìˆ˜ ---
def analyze_operating_point(df, models, target_q, target_h, m_col, q_col, h_col, k_col):
    if target_q <= 0 or target_h <= 0:
        return pd.DataFrame()

    results = []
    for model in models:
        model_df = df[df[m_col] == model].sort_values(q_col)
        # ë°ì´í„°ê°€ 2ê°œ ì´ìƒ ìˆì–´ì•¼ ë³´ê°„ ê°€ëŠ¥
        if len(model_df) < 2:
            continue

        # Target Qê°€ í•´ë‹¹ ëª¨ë¸ì˜ ìœ ëŸ‰ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ”ì§€ í™•ì¸
        if not (model_df[q_col].min() <= target_q <= model_df[q_col].max()):
            continue
            
        # np.interpë¥¼ ì‚¬ìš©í•´ target_q ì§€ì ì˜ ì„±ëŠ¥ ë³´ê°„
        interp_h = np.interp(target_q, model_df[q_col], model_df[h_col])

        # ë³´ê°„ëœ ì–‘ì •ì´ ëª©í‘œ ì–‘ì • ì´ìƒì¸ ëª¨ë¸ë§Œ ì„ ì •
        if interp_h >= target_h:
            interp_kw = np.interp(target_q, model_df[q_col], model_df[k_col]) if k_col and k_col in model_df else np.nan
            interp_eff = np.interp(target_q, model_df[q_col], model_df['Efficiency']) if 'Efficiency' in model_df else np.nan
            
            results.append({
                "ëª¨ë¸ëª…": model,
                "ìš”êµ¬ ìœ ëŸ‰ (Q)": target_q,
                "ìš”êµ¬ ì–‘ì • (H)": target_h,
                "ì˜ˆìƒ ì–‘ì • (H)": f"{interp_h:.2f}",
                "ì˜ˆìƒ ë™ë ¥ (kW)": f"{interp_kw:.2f}" if not np.isnan(interp_kw) else "N/A",
                "ì˜ˆìƒ íš¨ìœ¨ (%)": f"{interp_eff:.2f}" if not np.isnan(interp_eff) else "N/A",
                "ì„ ì • ê°€ëŠ¥ ì—¬ë¶€": "âœ…"
            })
            
    return pd.DataFrame(results)

# --- ì‹ ê·œ ê¸°ëŠ¥: í¸ì°¨ ì •ëŸ‰í™” í•¨ìˆ˜ ---
def quantify_deviation(df_ref, df_dev, m_col_r, q_col_r, h_col_r, k_col_r, m_col_d, q_col_d, h_col_d, k_col_d):
    # ë‘ ë°ì´í„°í”„ë ˆì„ì— ëª¨ë‘ ì¡´ì¬í•˜ëŠ” ëª¨ë¸ ì°¾ê¸°
    common_models = set(df_ref[m_col_r].unique()) & set(df_dev[m_col_d].unique())
    
    if not common_models:
        return pd.DataFrame()

    deviation_results = []
    for model in common_models:
        ref_model_df = df_ref[df_ref[m_col_r] == model].sort_values(q_col_r)
        dev_model_df = df_dev[df_dev[m_col_d] == model].sort_values(q_col_d)

        if len(ref_model_df) < 2: continue # ê¸°ì¤€ ë°ì´í„°ê°€ ë³´ê°„ì— ë¶€ì¡±í•˜ë©´ ê±´ë„ˆë›°ê¸°

        for _, dev_row in dev_model_df.iterrows():
            q_val = dev_row[q_col_d]
            
            # ê¸°ì¤€ ë°ì´í„°ì—ì„œ í˜„ì¬ ìœ ëŸ‰(q_val)ì— í•´ë‹¹í•˜ëŠ” ì„±ëŠ¥ ë³´ê°„
            ref_h = np.interp(q_val, ref_model_df[q_col_r], ref_model_df[h_col_r])
            ref_k = np.interp(q_val, ref_model_df[q_col_r], ref_model_df[k_col_r]) if k_col_r and k_col_r in ref_model_df else np.nan
            
            dev_h = dev_row[h_col_d]
            dev_k = dev_row[k_col_d] if k_col_d and k_col_d in dev_row else np.nan
            
            # í¸ì°¨ ê³„ì‚° (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
            h_dev_pct = ((dev_h - ref_h) / ref_h) * 100 if ref_h != 0 else 0
            k_dev_pct = ((dev_k - ref_k) / ref_k) * 100 if not np.isnan(ref_k) and ref_k != 0 else 0
            
            deviation_results.append({
                "ëª¨ë¸ëª…": model,
                "ì¸¡ì • ìœ ëŸ‰ (Q)": q_val,
                "ê¸°ì¤€ ì–‘ì • (H)": f"{ref_h:.2f}",
                "ì¸¡ì • ì–‘ì • (H)": f"{dev_h:.2f}",
                "ì–‘ì • í¸ì°¨ (%)": f"{h_dev_pct:.2f}%",
                "ê¸°ì¤€ ë™ë ¥ (kW)": f"{ref_k:.2f}" if not np.isnan(ref_k) else "N/A",
                "ì¸¡ì • ë™ë ¥ (kW)": f"{dev_k:.2f}" if not np.isnan(dev_k) else "N/A",
                "ë™ë ¥ í¸ì°¨ (%)": f"{k_dev_pct:.2f}%" if not np.isnan(ref_k) and ref_k != 0 else "N/A"
            })
            
    return pd.DataFrame(deviation_results)


# --- (ì´í•˜ ì½”ë“œëŠ” ì´ì „ê³¼ ê±°ì˜ ë™ì¼í•˜ë©°, ì‹ ê·œ ê¸°ëŠ¥ í˜¸ì¶œ ë¶€ë¶„ë§Œ ì¶”ê°€ë¨) ---

uploaded_file = st.file_uploader("Excel íŒŒì¼ ì—…ë¡œë“œ (.xlsx ë˜ëŠ” .xlsm)", type=["xlsx", "xlsm"])

SERIES_ORDER = [
    "XRF3", "XRF5", "XRF10", "XRF15", "XRF20", "XRF32",
    "XRF45", "XRF64", "XRF95", "XRF125", "XRF155", "XRF185",
    "XRF215", "XRF255"
]

def get_best_match_column(df, names):
    for n in names:
        for col in df.columns:
            if n in col:
                return col
    return None

def calculate_efficiency(df, q_col, h_col, k_col, q_unit='L/min'):
    if not all([q_col, h_col, k_col]):
        return df
    df_copy = df.copy()
    if q_unit == 'L/min': q_m3_s = df_copy[q_col] / 60000
    elif q_unit == 'm3/h': q_m3_s = df_copy[q_col] / 3600
    else: q_m3_s = df_copy[q_col]
    rho, g = 1000, 9.81
    power_kw = df_copy[k_col]
    efficiency = np.where(power_kw > 0, (rho * g * q_m3_s * df_copy[h_col]) / (power_kw * 1000) * 100, 0)
    df_copy['Efficiency'] = efficiency
    return df_copy

def load_sheet(name):
    try: df = pd.read_excel(uploaded_file, sheet_name=name)
    except Exception: return None, None, None, None, pd.DataFrame()
    mcol, qcol, hcol, kcol = get_best_match_column(df, ["ëª¨ë¸ëª…"]), get_best_match_column(df, ["ìœ ëŸ‰"]), get_best_match_column(df, ["ì–‘ì •"]), get_best_match_column(df, ["ë™ë ¥"])
    if not mcol or not qcol or not hcol: return None, None, None, None, pd.DataFrame()
    cols_to_check = [qcol, hcol]; 
    if kcol: cols_to_check.append(kcol)
    for col in cols_to_check:
        df = df.dropna(subset=[col])
        df = df[pd.to_numeric(df[col], errors='coerce').notna()]
        df[col] = pd.to_numeric(df[col])
    df['Series'] = df[mcol].astype(str).str.extract(r"(XRF\d+)"); df['Series'] = pd.Categorical(df['Series'], categories=SERIES_ORDER, ordered=True); df = df.sort_values('Series')
    df = calculate_efficiency(df, qcol, hcol, kcol, q_unit='L/min')
    return mcol, qcol, hcol, kcol, df

def render_filters(df, mcol, prefix):
    series_opts = df['Series'].dropna().unique().tolist()
    default_series = [series_opts[0]] if series_opts else []
    mode = st.radio("ë¶„ë¥˜ ê¸°ì¤€", ["ì‹œë¦¬ì¦ˆë³„","ëª¨ë¸ë³„"], key=prefix+"_mode", horizontal=True)
    if mode == "ì‹œë¦¬ì¦ˆë³„":
        sel = st.multiselect("ì‹œë¦¬ì¦ˆ ì„ íƒ", series_opts, default=default_series, key=prefix+"_series")
        df_f = df[df['Series'].isin(sel)] if sel else pd.DataFrame()
    else:
        model_opts = df[mcol].dropna().unique().tolist()
        default_model = [model_opts[0]] if model_opts else []
        sel = st.multiselect("ëª¨ë¸ ì„ íƒ", model_opts, default=default_model, key=prefix+"_models")
        df_f = df[df[mcol].isin(sel)] if sel else pd.DataFrame()
    return df_f

def add_traces(fig, df, mcol, xcol, ycol, models, mode, line_style=None, marker_style=None, name_suffix=""):
    for m in models:
        sub = df[df[mcol]==m].sort_values(xcol)
        if sub.empty: continue
        fig.add_trace(go.Scatter(x=sub[xcol], y=sub[ycol], mode=mode, name=m + name_suffix, line=line_style or {}, marker=marker_style or {}))

def add_bep_markers(fig, df, mcol, qcol, ycol, models, bep_y_col='Efficiency'):
    for m in models:
        model_df = df[df[mcol] == m]
        if not model_df.empty and bep_y_col in model_df.columns and not model_df[bep_y_col].isnull().all():
            bep_row = model_df.loc[model_df[bep_y_col].idxmax()]
            fig.add_trace(go.Scatter(x=[bep_row[qcol]], y=[bep_row[ycol]], mode='markers', marker=dict(symbol='star', size=15, color='gold'), name=f'{m} BEP'))

def add_guides(fig, hline, vline):
    if hline is not None and hline > 0: fig.add_shape(type="line", xref="paper", x0=0, x1=1, yref="y", y0=hline, y1=hline, line=dict(color="red", dash="dash"))
    if vline is not None and vline > 0: fig.add_shape(type="line", xref="x", x0=vline, x1=vline, yref="paper", y0=0, y1=1, line=dict(color="blue", dash="dash"))

def render_chart(fig, key):
    fig.update_layout(dragmode='pan', xaxis=dict(fixedrange=False), yaxis=dict(fixedrange=False))
    st.plotly_chart(fig, use_container_width=True, config={'scrollZoom': True, 'displaylogo': False}, key=key)

if uploaded_file:
    with st.spinner('ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì²˜ë¦¬í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
        m_r, q_r, h_r, k_r, df_r = load_sheet("reference data")
        m_c, q_c, h_c, k_c, df_c = load_sheet("catalog data")
        m_d, q_d, h_d, k_d, df_d = load_sheet("deviation data")

    # --- ì‹ ê·œ ê¸°ëŠ¥: í¸ì°¨ ë¶„ì„ íƒ­ ì¶”ê°€ ---
    tab_list = ["Total", "ì„±ëŠ¥ í¸ì°¨ ë¶„ì„", "Reference", "Catalog", "Deviation"]
    tabs = st.tabs(tab_list)

    with tabs[0]: # Total íƒ­
        st.subheader("ğŸ“Š Total - í†µí•© ê³¡ì„  ë° ìš´ì „ì  ë¶„ì„")
        df_f = render_filters(df_r, m_r, "total")
        models = df_f[m_r].unique().tolist() if not df_f.empty else []
        
        # --- ì‹ ê·œ ê¸°ëŠ¥: ìš´ì „ì  ë¶„ì„ UI ---
        with st.expander("ìš´ì „ì  ë¶„ì„ (Operating Point Analysis)"):
            op_col1, op_col2 = st.columns(2)
            with op_col1:
                target_q = st.number_input("ëª©í‘œ ìœ ëŸ‰ (Q)", value=0.0, format="%.2f", help="ì„ íƒí•œ íŒí”„ë“¤ì˜ ì„±ëŠ¥ì„ í™•ì¸í•  ëª©í‘œ ìœ ëŸ‰ì„ ì…ë ¥í•˜ì„¸ìš”.")
            with op_col2:
                target_h = st.number_input("ëª©í‘œ ì–‘ì • (H)", value=0.0, format="%.2f", help="ì´ ì–‘ì • ì´ìƒì„ ë§Œì¡±í•˜ëŠ” íŒí”„ë¥¼ ì°¾ìŠµë‹ˆë‹¤.")
            
            if st.button("ìš´ì „ì  ë¶„ì„ ì‹¤í–‰"):
                if not models:
                    st.warning("ë¨¼ì € ë¶„ì„í•  ì‹œë¦¬ì¦ˆë‚˜ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                else:
                    with st.spinner("ì„ íƒëœ ëª¨ë¸ë“¤ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                        op_results_df = analyze_operating_point(df_r, models, target_q, target_h, m_r, q_r, h_r, k_r)
                        if not op_results_df.empty:
                            st.success(f"ì´ {len(op_results_df)}ê°œì˜ ëª¨ë¸ì´ ìš”êµ¬ ì„±ëŠ¥ì„ ë§Œì¡±í•©ë‹ˆë‹¤.")
                            st.dataframe(op_results_df, use_container_width=True)
                        else:
                            st.info("ìš”êµ¬ ì„±ëŠ¥ì„ ë§Œì¡±í•˜ëŠ” ëª¨ë¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ëª©í‘œê°’ì„ ì¡°ì •í•˜ê±°ë‚˜ ë‹¤ë¥¸ ëª¨ë¸ì„ ì„ íƒí•´ë³´ì„¸ìš”.")
        
        st.markdown("---")
        # (ì´í•˜ ê·¸ë˜í”„ í‘œì‹œëŠ” ì´ì „ê³¼ ë™ì¼)
        ref_show = st.checkbox("Reference í‘œì‹œ", key="total_ref", value=True)
        cat_show = st.checkbox("Catalog í‘œì‹œ", key="total_cat")
        dev_show = st.checkbox("Deviation í‘œì‹œ", key="total_dev")
        
        st.markdown("#### Q-H (í† ì¶œëŸ‰-í† ì¶œì–‘ì •)")
        fig_h = go.Figure();
        if ref_show: add_traces(fig_h, df_r, m_r, q_r, h_r, models, 'lines+markers'); add_bep_markers(fig_h, df_r, m_r, q_r, h_r, models)
        if cat_show: add_traces(fig_h, df_c, m_c, q_c, h_c, models, 'lines+markers', line_style=dict(dash='dot'))
        if dev_show: add_traces(fig_h, df_d, m_d, q_d, h_d, models, 'markers')
        if 'target_q' in locals() and target_q > 0: fig_h.add_trace(go.Scatter(x=[target_q], y=[target_h], mode='markers', marker=dict(symbol='cross', size=15, color='magenta'), name='ìš´ì „ì '))
        render_chart(fig_h, key="total_qh")
        
        # Q-kW, Q-Eff ê·¸ë˜í”„ ìƒëµ (ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼)

    with tabs[1]: # ì„±ëŠ¥ í¸ì°¨ ë¶„ì„ íƒ­
        st.subheader("ğŸ”¬ ì„±ëŠ¥ í¸ì°¨ ì •ëŸ‰ ë¶„ì„")
        st.info("Reference ë°ì´í„°ì™€ Deviation ë°ì´í„°ë¥¼ ë¹„êµí•˜ì—¬ ì„±ëŠ¥ í¸ì°¨ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.")
        
        if df_r.empty or df_d.empty:
            st.warning("í¸ì°¨ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” 'reference data'ì™€ 'deviation data' ì‹œíŠ¸ê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            with st.spinner("í¸ì°¨ë¥¼ ê³„ì‚°í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                deviation_df = quantify_deviation(df_r, df_d, m_r, q_r, h_r, k_r, m_d, q_d, h_d, k_d)
                st.dataframe(deviation_df, use_container_width=True)

    # ë‚˜ë¨¸ì§€ ê°œë³„ íƒ­ë“¤ (2, 3, 4)
    for idx, sheet in enumerate(["reference data", "catalog data", "deviation data"]):
        with tabs[idx+2]:
            st.subheader(sheet.title())
            if sheet == "reference data": mcol,qcol,hcol,kcol,df = m_r,q_r,h_r,k_r,df_r
            elif sheet == "catalog data": mcol,qcol,hcol,kcol,df = m_c,q_c,h_c,k_c,df_c
            else: mcol,qcol,hcol,kcol,df = m_d,q_d,h_d,k_d,df_d
            if df.empty: st.warning(f"'{sheet}' ì‹œíŠ¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."); continue
            
            df_f = render_filters(df, mcol, sheet)
            models = df_f[mcol].unique().tolist() if not df_f.empty else []
            if not models: st.info("ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”."); continue

            st.markdown("#### Q-H (í† ì¶œëŸ‰-í† ì¶œì–‘ì •)")
            fig1 = go.Figure()
            mode1, style1 = ('markers', None) if sheet=='deviation data' else ('lines+markers', dict(dash='dot') if sheet=='catalog data' else None)
            add_traces(fig1, df_f, mcol, qcol, hcol, models, mode1, line_style=style1)
            if 'Efficiency' in df_f.columns: add_bep_markers(fig1, df_f, mcol, qcol, hcol, models)
            render_chart(fig1, key=f"{sheet}_qh")
            
            # Q-kW, Q-Eff, ë°ì´í„° í…Œì´ë¸” ìƒëµ (ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼)
else:
    st.info("ì‹œì‘í•˜ë ¤ë©´ Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
