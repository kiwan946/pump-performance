import streamlit as st

import pandas as pd

import plotly.graph_objs as go

import plotly.figure_factory as ff

import numpy as np

from scipy.stats import t



# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •

st.set_page_config(page_title="Dooch XRL(F) ì„±ëŠ¥ ê³¡ì„  ë·°ì–´ v1.0", layout="wide")

st.title("ğŸ“Š Dooch XRL(F) ì„±ëŠ¥ ê³¡ì„  ë·°ì–´ v1.0")



# --- ìœ í‹¸ë¦¬í‹° ë° ê¸°ë³¸ ë¶„ì„ í•¨ìˆ˜ë“¤ (ì´ì „ê³¼ ë™ì¼) ---

SERIES_ORDER = ["XRF3", "XRF5", "XRF10", "XRF15", "XRF20", "XRF32", "XRF45", "XRF64", "XRF95", "XRF125", "XRF155", "XRF185", "XRF215", "XRF255"]



def get_best_match_column(df, names):

Â  Â  if df is None or df.empty: return None

Â  Â  for n in names:

Â  Â  Â  Â  for col in df.columns:

Â  Â  Â  Â  Â  Â  if n in col.strip():

Â  Â  Â  Â  Â  Â  Â  Â  return col

Â  Â  return None



def calculate_efficiency(df, q_col, h_col, k_col):

Â  Â  if not all(col and col in df.columns for col in [q_col, h_col, k_col]): return df

Â  Â  df_copy = df.copy()

Â  Â  hydraulic_power = 0.163 * df_copy[q_col] * df_copy[h_col]

Â  Â  shaft_power = df_copy[k_col]

Â  Â  df_copy['Efficiency'] = np.where(shaft_power > 0, (hydraulic_power / shaft_power) * 100, 0)

Â  Â  return df_copy



def load_sheet(uploaded_file, sheet_name):

Â  Â  try:

Â  Â  Â  Â  df = pd.read_excel(uploaded_file, sheet_name=sheet_name)

Â  Â  Â  Â  df.columns = df.columns.str.strip()

Â  Â  Â  Â  mcol = get_best_match_column(df, ["ëª¨ë¸ëª…", "ëª¨ë¸", "Model"])

Â  Â  Â  Â  if not mcol: return None, pd.DataFrame()

Â  Â  Â  Â  if 'Series' in df.columns: df = df.drop(columns=['Series'])

Â  Â  Â  Â  df['Series'] = df[mcol].astype(str).str.extract(r"(XRF\d+)")

Â  Â  Â  Â  df['Series'] = pd.Categorical(df['Series'], categories=SERIES_ORDER, ordered=True)

Â  Â  Â  Â  df = df.sort_values('Series')

Â  Â  Â  Â  return mcol, df

Â  Â  except Exception:

Â  Â  Â  Â  return None, pd.DataFrame()



def process_data(df, q_col, h_col, k_col):

Â  Â  if df.empty: return df

Â  Â  temp_df = df.copy()

Â  Â  for col in [q_col, h_col, k_col]:

Â  Â  Â  Â  if col and col in temp_df.columns:

Â  Â  Â  Â  Â  Â  temp_df = temp_df.dropna(subset=[col])

Â  Â  Â  Â  Â  Â  temp_df = temp_df[pd.to_numeric(temp_df[col], errors='coerce').notna()]

Â  Â  Â  Â  Â  Â  temp_df[col] = pd.to_numeric(temp_df[col])

Â  Â  return calculate_efficiency(temp_df, q_col, h_col, k_col)



def analyze_operating_point(df, models, target_q, target_h, m_col, q_col, h_col, k_col):

Â  Â  if target_h <= 0: return pd.DataFrame()

Â  Â  results = []



Â  Â  if target_q == 0:

Â  Â  Â  Â  for model in models:

Â  Â  Â  Â  Â  Â  model_df = df[df[m_col] == model].sort_values(q_col)

Â  Â  Â  Â  Â  Â  if model_df.empty: continue

Â  Â  Â  Â  Â  Â  churn_h = model_df.iloc[0][h_col]

Â  Â  Â  Â  Â  Â  if churn_h >= target_h:

Â  Â  Â  Â  Â  Â  Â  Â  churn_kw = model_df.iloc[0][k_col] if k_col and k_col in model_df.columns else np.nan

Â  Â  Â  Â  Â  Â  Â  Â  churn_eff = np.interp(0, model_df[q_col], model_df['Efficiency']) if 'Efficiency' in model_df.columns else 0

Â  Â  Â  Â  Â  Â  Â  Â  results.append({"ëª¨ë¸ëª…": model, "ìš”êµ¬ ìœ ëŸ‰": "0 (ì²´ì ˆ)", "ìš”êµ¬ ì–‘ì •": target_h, "ì˜ˆìƒ ì–‘ì •": f"{churn_h:.2f}", "ì˜ˆìƒ ë™ë ¥(kW)": f"{churn_kw:.2f}", "ì˜ˆìƒ íš¨ìœ¨(%)": f"{churn_eff:.2f}", "ì„ ì • ê°€ëŠ¥": "âœ…"})

Â  Â  Â  Â  return pd.DataFrame(results)



Â  Â  for model in models:

Â  Â  Â  Â  model_df = df[df[m_col] == model].sort_values(q_col)

Â  Â  Â  Â  if len(model_df) < 2 or not (model_df[q_col].min() <= target_q <= model_df[q_col].max()): continue

Â  Â  Â  Â  interp_h = np.interp(target_q, model_df[q_col], model_df[h_col])

Â  Â  Â  Â Â 

Â  Â  Â  Â  if interp_h >= target_h:

Â  Â  Â  Â  Â  Â  interp_kw = np.interp(target_q, model_df[q_col], model_df[k_col]) if k_col and k_col in model_df.columns else np.nan

Â  Â  Â  Â  Â  Â  interp_eff = np.interp(target_q, model_df[q_col], model_df['Efficiency']) if 'Efficiency' in model_df.columns else np.nan

Â  Â  Â  Â  Â  Â  results.append({"ëª¨ë¸ëª…": model, "ìš”êµ¬ ìœ ëŸ‰": target_q, "ìš”êµ¬ ì–‘ì •": target_h, "ì˜ˆìƒ ì–‘ì •": f"{interp_h:.2f}", "ì˜ˆìƒ ë™ë ¥(kW)": f"{interp_kw:.2f}", "ì˜ˆìƒ íš¨ìœ¨(%)": f"{interp_eff:.2f}", "ì„ ì • ê°€ëŠ¥": "âœ…"})

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  h_values_rev = model_df[h_col].values[::-1]

Â  Â  Â  Â  Â  Â  q_values_rev = model_df[q_col].values[::-1]



Â  Â  Â  Â  Â  Â  if target_h <= model_df[h_col].max() and target_h >= model_df[h_col].min():

Â  Â  Â  Â  Â  Â  Â  Â  q_required = np.interp(target_h, h_values_rev, q_values_rev)

Â  Â  Â  Â  Â  Â  Â  Â  if 0.95 * target_q <= q_required < target_q:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  correction_pct = (1 - (q_required / target_q)) * 100

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  status_text = f"ìœ ëŸ‰ {correction_pct:.1f}% ë³´ì • ì „ì œ ì‚¬ìš© ê°€ëŠ¥"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  interp_kw_corr = np.interp(q_required, model_df[q_col], model_df[k_col]) if k_col and k_col in model_df.columns else np.nan

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  interp_eff_corr = np.interp(q_required, model_df[q_col], model_df['Efficiency']) if 'Efficiency' in model_df.columns else np.nan

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  results.append({"ëª¨ë¸ëª…": model, "ìš”êµ¬ ìœ ëŸ‰": target_q, "ìš”êµ¬ ì–‘ì •": target_h, "ì˜ˆìƒ ì–‘ì •": f"{target_h:.2f} (at Q={q_required:.2f})", "ì˜ˆìƒ ë™ë ¥(kW)": f"{interp_kw_corr:.2f}", "ì˜ˆìƒ íš¨ìœ¨(%)": f"{interp_eff_corr:.2f}", "ì„ ì • ê°€ëŠ¥": status_text})

Â  Â Â 

Â  Â  return pd.DataFrame(results)



def analyze_fire_pump_point(df, models, target_q, target_h, m_col, q_col, h_col, k_col):

Â  Â  if target_q <= 0 or target_h <= 0: return pd.DataFrame()

Â  Â  results = []

Â  Â  for model in models:

Â  Â  Â  Â  model_df = df[df[m_col] == model].sort_values(q_col)

Â  Â  Â  Â  if len(model_df) < 2: continue

Â  Â  Â  Â Â 

Â  Â  Â  Â  interp_h_rated = np.interp(target_q, model_df[q_col], model_df[h_col], left=np.nan, right=np.nan)

Â  Â  Â  Â  h_churn = model_df.iloc[0][h_col]

Â  Â  Â  Â  q_overload = 1.5 * target_q

Â  Â  Â  Â  interp_h_overload = np.interp(q_overload, model_df[q_col], model_df[h_col], left=np.nan, right=np.nan)



Â  Â  Â  Â  if not np.isnan(interp_h_rated) and interp_h_rated >= target_h:

Â  Â  Â  Â  Â  Â  cond1_ok = h_churn <= (1.40 * target_h)

Â  Â  Â  Â  Â  Â  cond2_ok = (not np.isnan(interp_h_overload)) and (interp_h_overload >= (0.65 * target_h))

Â  Â  Â  Â  Â  Â  if cond1_ok and cond2_ok:

Â  Â  Â  Â  Â  Â  Â  Â  interp_kw = np.interp(target_q, model_df[q_col], model_df[k_col]) if k_col and k_col in model_df.columns else np.nan

Â  Â  Â  Â  Â  Â  Â  Â  results.append({"ëª¨ë¸ëª…": model, "ì •ê²© ì˜ˆìƒ ì–‘ì •": f"{interp_h_rated:.2f}", "ì²´ì ˆ ì–‘ì • (â‰¤{1.4*target_h:.2f})": f"{h_churn:.2f}", "ìµœëŒ€ìš´ì „ ì–‘ì • (â‰¥{0.65*target_h:.2f})": f"{interp_h_overload:.2f}", "ì˜ˆìƒ ë™ë ¥(kW)": f"{interp_kw:.2f}", "ì„ ì • ê°€ëŠ¥": "âœ…"})

Â  Â  Â  Â  Â  Â  Â  Â  continue



Â  Â  Â  Â  h_values_rev = model_df[h_col].values[::-1]

Â  Â  Â  Â  q_values_rev = model_df[q_col].values[::-1]



Â  Â  Â  Â  if target_h <= model_df[h_col].max() and target_h >= model_df[h_col].min():

Â  Â  Â  Â  Â  Â  q_required = np.interp(target_h, h_values_rev, q_values_rev)

Â  Â  Â  Â  Â  Â  if 0.95 * target_q <= q_required < target_q:

Â  Â  Â  Â  Â  Â  Â  Â  q_overload_corr = 1.5 * q_required

Â  Â  Â  Â  Â  Â  Â  Â  interp_h_overload_corr = np.interp(q_overload_corr, model_df[q_col], model_df[h_col], left=np.nan, right=np.nan)

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  cond1_ok = h_churn <= (1.40 * target_h)

Â  Â  Â  Â  Â  Â  Â  Â  cond2_ok = (not np.isnan(interp_h_overload_corr)) and (interp_h_overload_corr >= (0.65 * target_h))



Â  Â  Â  Â  Â  Â  Â  Â  if cond1_ok and cond2_ok:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  correction_pct = (1 - (q_required / target_q)) * 100

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  status_text = f"ìœ ëŸ‰ {correction_pct:.1f}% ë³´ì • ì „ì œ ì‚¬ìš© ê°€ëŠ¥"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  interp_kw_corr = np.interp(q_required, model_df[q_col], model_df[k_col]) if k_col and k_col in model_df.columns else np.nan

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  results.append({"ëª¨ë¸ëª…": model, "ì •ê²© ì˜ˆìƒ ì–‘ì •": f"{target_h:.2f} (at Q={q_required:.2f})", "ì²´ì ˆ ì–‘ì • (â‰¤{1.4*target_h:.2f})": f"{h_churn:.2f}", "ìµœëŒ€ìš´ì „ ì–‘ì • (â‰¥{0.65*target_h:.2f})": f"{interp_h_overload_corr:.2f}", "ì˜ˆìƒ ë™ë ¥(kW)": f"{interp_kw_corr:.2f}", "ì„ ì • ê°€ëŠ¥": status_text})

Â  Â Â 

Â  Â  return pd.DataFrame(results)



def render_filters(df, mcol, prefix):

Â  Â  if df is None or df.empty or mcol is None or 'Series' not in df.columns:

Â  Â  Â  Â  st.warning("í•„í„°ë§í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

Â  Â  Â  Â  return pd.DataFrame()

Â  Â  series_opts = df['Series'].dropna().unique().tolist()

Â  Â  default_series = [series_opts[0]] if series_opts else []

Â  Â  mode = st.radio("ë¶„ë¥˜ ê¸°ì¤€", ["ì‹œë¦¬ì¦ˆë³„", "ëª¨ë¸ë³„"], key=f"{prefix}_mode", horizontal=True)

Â  Â  if mode == "ì‹œë¦¬ì¦ˆë³„":

Â  Â  Â  Â  sel = st.multiselect("ì‹œë¦¬ì¦ˆ ì„ íƒ", series_opts, default=default_series, key=f"{prefix}_series")

Â  Â  Â  Â  df_f = df[df['Series'].isin(sel)] if sel else pd.DataFrame()

Â  Â  else:

Â  Â  Â  Â  model_opts = df[mcol].dropna().unique().tolist()

Â  Â  Â  Â  default_model = [model_opts[0]] if model_opts else []

Â  Â  Â  Â  sel = st.multiselect("ëª¨ë¸ ì„ íƒ", model_opts, default=default_model, key=f"{prefix}_models")

Â  Â  Â  Â  df_f = df[df[mcol].isin(sel)] if sel else pd.DataFrame()

Â  Â  return df_f



def add_traces(fig, df, mcol, xcol, ycol, models, mode, line_style=None, name_suffix=""):

Â  Â  for m in models:

Â  Â  Â  Â  sub = df[df[mcol] == m].sort_values(xcol)

Â  Â  Â  Â  if sub.empty or ycol not in sub.columns: continue

Â  Â  Â  Â  fig.add_trace(go.Scatter(x=sub[xcol], y=sub[ycol], mode=mode, name=m + name_suffix, line=line_style or {}))



def add_bep_markers(fig, df, mcol, qcol, ycol, models):

Â  Â  for m in models:

Â  Â  Â  Â  model_df = df[df[mcol] == m]

Â  Â  Â  Â  if not model_df.empty and 'Efficiency' in model_df.columns and not model_df['Efficiency'].isnull().all():

Â  Â  Â  Â  Â  Â  bep_row = model_df.loc[model_df['Efficiency'].idxmax()]

Â  Â  Â  Â  Â  Â  fig.add_trace(go.Scatter(x=[bep_row[qcol]], y=[bep_row[ycol]], mode='markers', marker=dict(symbol='star', size=15, color='gold'), name=f'{m} BEP'))



def add_guide_lines(fig, h_line, v_line):

Â  Â  if h_line is not None and h_line > 0:

Â  Â  Â  Â  fig.add_shape(type="line", x0=0, x1=1, xref="paper", y0=h_line, y1=h_line, yref="y", line=dict(color="gray", dash="dash"))

Â  Â  if v_line is not None and v_line > 0:

Â  Â  Â  Â  fig.add_shape(type="line", x0=v_line, x1=v_line, xref="x", y0=0, y1=1, yref="paper", line=dict(color="gray", dash="dash"))



def render_chart(fig, key):

Â  Â  fig.update_layout(dragmode='pan', xaxis=dict(fixedrange=False), yaxis=dict(fixedrange=False), legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1))

Â  Â  st.plotly_chart(fig, use_container_width=True, config={'scrollZoom': True, 'displaylogo': False}, key=key)



def perform_validation_analysis(df_r, df_d, m_r, m_d, q_r, q_d, y_r_col, y_d_col, test_id_col, models_to_validate, analysis_type):

Â  Â  all_results = {}

Â  Â  for model in models_to_validate:

Â  Â  Â  Â  model_summary = []

Â  Â  Â  Â  model_r_df = df_r[(df_r[m_r] == model) & (df_r[y_r_col].notna())].sort_values(by=q_r)

Â  Â  Â  Â  model_d_df = df_d[(df_d[m_d] == model) & (df_d[y_d_col].notna())]

Â  Â  Â  Â  if model_r_df.empty or model_d_df.empty: continue

Â  Â  Â  Â Â 

Â  Â  Â  Â  max_q = model_r_df[q_r].max()

Â  Â  Â  Â  validation_q = np.linspace(0, max_q, 10)

Â  Â  Â  Â  ref_y = np.interp(validation_q, model_r_df[q_r], model_r_df[y_r_col])

Â  Â  Â  Â  test_ids = model_d_df[test_id_col].unique()

Â  Â  Â  Â  interpolated_y_samples = {q: [] for q in validation_q}

Â  Â  Â  Â  for test_id in test_ids:

Â  Â  Â  Â  Â  Â  test_df = model_d_df[model_d_df[test_id_col] == test_id].sort_values(by=q_d)

Â  Â  Â  Â  Â  Â  if len(test_df) < 2: continue

Â  Â  Â  Â  Â  Â  interp_y = np.interp(validation_q, test_df[q_d], test_df[y_d_col])

Â  Â  Â  Â  Â  Â  for i, q in enumerate(validation_q):

Â  Â  Â  Â  Â  Â  Â  Â  interpolated_y_samples[q].append(interp_y[i])

Â  Â  Â  Â Â 

Â  Â  Â  Â  for i, q in enumerate(validation_q):

Â  Â  Â  Â  Â  Â  samples = np.array(interpolated_y_samples[q])

Â  Â  Â  Â  Â  Â  n = len(samples)

Â  Â  Â  Â  Â  Â  base_col_name = f"ê¸°ì¤€ {analysis_type}"

Â  Â  Â  Â  Â  Â  mean_col_name = "í‰ê· "

Â  Â  Â  Â  Â  Â  if n < 2:

Â  Â  Â  Â  Â  Â  Â  Â  model_summary.append({

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "ëª¨ë¸ëª…": model, "ê²€ì¦ ìœ ëŸ‰(Q)": q, base_col_name: ref_y[i],Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "ì‹œí—˜ íšŸìˆ˜(n)": n, mean_col_name: np.nan, "í‘œì¤€í¸ì°¨": np.nan,Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "95% CI í•˜í•œ": np.nan, "95% CI ìƒí•œ": np.nan, "ìœ íš¨ì„±": "íŒë‹¨ë¶ˆê°€",

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "_original_q": q

Â  Â  Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  mean_y, std_dev = np.mean(samples), np.std(samples, ddof=1)

Â  Â  Â  Â  Â  Â  std_err = std_dev / np.sqrt(n)

Â  Â  Â  Â  Â  Â  t_critical = t.ppf(0.975, df=n-1)

Â  Â  Â  Â  Â  Â  margin_of_error = t_critical * std_err

Â  Â  Â  Â  Â  Â  ci_lower, ci_upper = mean_y - margin_of_error, mean_y + margin_of_error

Â  Â  Â  Â  Â  Â  is_valid = "âœ… ìœ íš¨" if ci_lower <= ref_y[i] <= ci_upper else "âŒ ë²—ì–´ë‚¨"

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  model_summary.append({

Â  Â  Â  Â  Â  Â  Â  Â  "ëª¨ë¸ëª…": model, "ê²€ì¦ ìœ ëŸ‰(Q)": f"{q:.2f}", base_col_name: f"{ref_y[i]:.2f}",

Â  Â  Â  Â  Â  Â  Â  Â  "ì‹œí—˜ íšŸìˆ˜(n)": n, mean_col_name: f"{mean_y:.2f}", "í‘œì¤€í¸ì°¨": f"{std_dev:.2f}",

Â  Â  Â  Â  Â  Â  Â  Â  "95% CI í•˜í•œ": f"{ci_lower:.2f}", "95% CI ìƒí•œ": f"{ci_upper:.2f}", "ìœ íš¨ì„±": is_valid,

Â  Â  Â  Â  Â  Â  Â  Â  "_original_q": q

Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â Â 

Â  Â  Â  Â  all_results[model] = { 'summary': pd.DataFrame(model_summary), 'samples': interpolated_y_samples }

Â  Â  return all_results



def display_validation_output(model, validation_data, analysis_type, df_r, df_d, m_r, m_d, q_r, q_d, y_r_col, y_d_col, test_id_col):

Â  Â  if model not in validation_data or validation_data[model]['summary'].empty:

Â  Â  Â  Â  st.warning(f"'{model}' ëª¨ë¸ì— ëŒ€í•œ {analysis_type} ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

Â  Â  Â  Â  return



Â  Â  model_data = validation_data[model]

Â  Â  model_summary_df = model_data['summary']

Â  Â  model_samples = model_data['samples']

Â  Â  base_col_name = f"ê¸°ì¤€ {analysis_type}"

Â  Â Â 

Â  Â  st.markdown(f"#### ë¶„ì„ ê²°ê³¼ ìš”ì•½ ({analysis_type})")

Â  Â  display_summary = model_summary_df.drop(columns=['_original_q']).set_index('ëª¨ë¸ëª…')

Â  Â  st.dataframe(display_summary, use_container_width=True)

Â  Â Â 

Â  Â  st.markdown(f"#### ëª¨ë¸ë³„ ìƒì„¸ ê²°ê³¼ ì‹œê°í™” ({analysis_type})")

Â  Â  fig_main = go.Figure()

Â  Â  numeric_cols = ["ê²€ì¦ ìœ ëŸ‰(Q)", base_col_name, "95% CI í•˜í•œ", "95% CI ìƒí•œ"]

Â  Â  for col in numeric_cols: model_summary_df[col] = pd.to_numeric(model_summary_df[col], errors='coerce')

Â  Â Â 

Â  Â  fig_main.add_trace(go.Scatter(x=model_summary_df['ê²€ì¦ ìœ ëŸ‰(Q)'], y=model_summary_df['95% CI ìƒí•œ'], fill=None, mode='lines', line_color='rgba(0,100,80,0.2)', name='95% CI ìƒí•œ'))

Â  Â  fig_main.add_trace(go.Scatter(x=model_summary_df['ê²€ì¦ ìœ ëŸ‰(Q)'], y=model_summary_df['95% CI í•˜í•œ'], fill='tonexty', mode='lines', line_color='rgba(0,100,80,0.2)', name='95% CI í•˜í•œ'))

Â  Â Â 

Â  Â  model_d_df_vis = df_d[(df_d[m_d] == model) & (df_d[y_d_col].notna())]; test_ids_vis = model_d_df_vis[test_id_col].unique()

Â  Â  for test_id in test_ids_vis:

Â  Â  Â  Â  test_df_vis = model_d_df_vis[model_d_df_vis[test_id_col] == test_id].sort_values(by=q_d)

Â  Â  Â  Â  fig_main.add_trace(go.Scatter(x=test_df_vis[q_d], y=test_df_vis[y_d_col], mode='lines', line=dict(width=1, color='grey'), name=f'ì‹œí—˜ {test_id}', opacity=0.5, showlegend=False))

Â  Â Â 

Â  Â  model_r_df_vis = df_r[(df_r[m_r] == model) & (df_r[y_r_col].notna())].sort_values(by=q_r)

Â  Â  fig_main.add_trace(go.Scatter(x=model_r_df_vis[q_r], y=model_r_df_vis[y_r_col], mode='lines+markers', line=dict(color='blue', width=3), name='Reference Curve'))

Â  Â Â 

Â  Â  if analysis_type == 'ì–‘ì •':

Â  Â  Â  Â  upper_limit = model_summary_df[base_col_name] * 1.05

Â  Â  Â  Â  lower_limit = model_summary_df[base_col_name] * 0.95

Â  Â  Â  Â  fig_main.add_trace(go.Scatter(x=model_summary_df['ê²€ì¦ ìœ ëŸ‰(Q)'], y=upper_limit, mode='lines', name='ì–‘ì • ìƒí•œ (+5%)', line=dict(color='orange', dash='dash')))

Â  Â  Â  Â  fig_main.add_trace(go.Scatter(x=model_summary_df['ê²€ì¦ ìœ ëŸ‰(Q)'], y=lower_limit, mode='lines', name='ì–‘ì • í•˜í•œ (-5%)', line=dict(color='orange', dash='dash')))



Â  Â  valid_points = model_summary_df[model_summary_df['ìœ íš¨ì„±'] == 'âœ… ìœ íš¨']; invalid_points = model_summary_df[model_summary_df['ìœ íš¨ì„±'] == 'âŒ ë²—ì–´ë‚¨']

Â  Â  fig_main.add_trace(go.Scatter(x=valid_points['ê²€ì¦ ìœ ëŸ‰(Q)'], y=valid_points[base_col_name], mode='markers', marker=dict(color='green', size=10, symbol='circle'), name='ìœ íš¨ í¬ì¸íŠ¸'))

Â  Â  fig_main.add_trace(go.Scatter(x=invalid_points['ê²€ì¦ ìœ ëŸ‰(Q)'], y=invalid_points[base_col_name], mode='markers', marker=dict(color='red', size=10, symbol='x'), name='ë²—ì–´ë‚¨ í¬ì¸íŠ¸'))

Â  Â Â 

Â  Â  fig_main.update_layout(yaxis_title=analysis_type)

Â  Â  st.plotly_chart(fig_main, use_container_width=True)



Â  Â  with st.expander(f"ê²€ì¦ ìœ ëŸ‰ ì§€ì ë³„ {analysis_type} ë°ì´í„° ë¶„í¬í‘œ ë³´ê¸°"):

Â  Â  Â  Â  for idx, row in model_summary_df.iterrows():

Â  Â  Â  Â  Â  Â  q_point_original = row['_original_q']

Â  Â  Â  Â  Â  Â  samples = model_samples.get(q_point_original, [])

Â  Â  Â  Â  Â  Â  if not samples or row['ì‹œí—˜ íšŸìˆ˜(n)'] < 2: continue

Â  Â  Â  Â  Â  Â  q_point_str, ref_y_point, mean_y, std_y, n_samples = row['ê²€ì¦ ìœ ëŸ‰(Q)'], float(row[base_col_name]), float(row['í‰ê· ']), float(row['í‘œì¤€í¸ì°¨']), int(row['ì‹œí—˜ íšŸìˆ˜(n)'])

Â  Â  Â  Â  Â  Â  st.markdown(f"**Q = {q_point_str}**")

Â  Â  Â  Â  Â  Â  st.markdown(f"<small>í‰ê· : {mean_y:.2f} | í‘œì¤€í¸ì°¨: {std_y:.2f} | n: {n_samples}</small>", unsafe_allow_html=True)

Â  Â  Â  Â  Â  Â  fig_dist = ff.create_distplot([samples], ['ì‹œí—˜ ë°ì´í„°'], show_hist=False, show_rug=True)

Â  Â  Â  Â  Â  Â  fig_dist.add_vline(x=ref_y_point, line_width=2, line_dash="dash", line_color="red")

Â  Â  Â  Â  Â  Â  fig_dist.add_vline(x=mean_y, line_width=2, line_dash="dot", line_color="blue")

Â  Â  Â  Â  Â  Â  fig_dist.update_layout(title_text=None, xaxis_title=analysis_type, yaxis_title="ë°€ë„", height=300, margin=dict(l=20,r=20,t=5,b=20), showlegend=False)

Â  Â  Â  Â  Â  Â  st.plotly_chart(fig_dist, use_container_width=True, config={'displayModeBar': False})

Â  Â  Â  Â  Â  Â  st.markdown("---")



# --- ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§ ---

uploaded_file = st.file_uploader("Excel íŒŒì¼ ì—…ë¡œë“œ (.xlsx ë˜ëŠ” .xlsm)", type=["xlsx", "xlsm"])

if uploaded_file:

Â  Â  m_r, df_r_orig = load_sheet(uploaded_file, "reference data"); m_c, df_c_orig = load_sheet(uploaded_file, "catalog data"); m_d, df_d_orig = load_sheet(uploaded_file, "deviation data")

Â  Â  if df_r_orig.empty: st.error("ì˜¤ë¥˜: 'reference data' ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ 'ëª¨ë¸ëª…' ê´€ë ¨ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

Â  Â  else:

Â  Â  Â  Â  st.sidebar.title("âš™ï¸ ë¶„ì„ ì„¤ì •"); st.sidebar.markdown("### Total íƒ­ & ìš´ì „ì  ë¶„ì„ ì»¬ëŸ¼ ì§€ì •")

Â  Â  Â  Â  all_columns_r = df_r_orig.columns.tolist()

Â  Â  Â  Â  def safe_get_index(items, value, default=0):

Â  Â  Â  Â  Â  Â  try: return items.index(value)

Â  Â  Â  Â  Â  Â  except (ValueError, TypeError): return default

Â  Â  Â  Â  q_auto_r = get_best_match_column(df_r_orig, ["í† ì¶œëŸ‰", "ìœ ëŸ‰"]); h_auto_r = get_best_match_column(df_r_orig, ["í† ì¶œì–‘ì •", "ì „ì–‘ì •"]); k_auto_r = get_best_match_column(df_r_orig, ["ì¶•ë™ë ¥"])

Â  Â  Â  Â  q_col_total = st.sidebar.selectbox("ìœ ëŸ‰ (Flow) ì»¬ëŸ¼", all_columns_r, index=safe_get_index(all_columns_r, q_auto_r))

Â  Â  Â  Â  h_col_total = st.sidebar.selectbox("ì–‘ì • (Head) ì»¬ëŸ¼", all_columns_r, index=safe_get_index(all_columns_r, h_auto_r))

Â  Â  Â  Â  k_col_total = st.sidebar.selectbox("ì¶•ë™ë ¥ (Power) ì»¬ëŸ¼", all_columns_r, index=safe_get_index(all_columns_r, k_auto_r))

Â  Â  Â  Â  q_c, h_c, k_c = (get_best_match_column(df_c_orig, ["í† ì¶œëŸ‰", "ìœ ëŸ‰"]), get_best_match_column(df_c_orig, ["í† ì¶œì–‘ì •", "ì „ì–‘ì •"]), get_best_match_column(df_c_orig, ["ì¶•ë™ë ¥"]))

Â  Â  Â  Â  q_d, h_d, k_d = (get_best_match_column(df_d_orig, ["í† ì¶œëŸ‰", "ìœ ëŸ‰"]), get_best_match_column(df_d_orig, ["í† ì¶œì–‘ì •", "ì „ì–‘ì •"]), get_best_match_column(df_d_orig, ["ì¶•ë™ë ¥"]))

Â  Â  Â  Â  test_id_col_d = get_best_match_column(df_d_orig, ["ì‹œí—˜ë²ˆí˜¸", "Test No", "Test ID"])

Â  Â  Â  Â  if not df_d_orig.empty and test_id_col_d:

Â  Â  Â  Â  Â  Â  df_d_orig[test_id_col_d] = df_d_orig[test_id_col_d].astype(str).str.strip()

Â  Â  Â  Â  Â  Â  df_d_orig[test_id_col_d].replace(['', 'nan'], np.nan, inplace=True)

Â  Â  Â  Â  Â  Â  df_d_orig[test_id_col_d] = df_d_orig[test_id_col_d].ffill()

Â  Â  Â  Â  df_r = process_data(df_r_orig, q_col_total, h_col_total, k_col_total); df_c = process_data(df_c_orig, q_c, h_c, k_c); df_d = process_data(df_d_orig, q_d, h_d, k_d)

Â  Â  Â  Â  tab_list = ["Total", "Reference", "Catalog", "Deviation", "Validation"]; tabs = st.tabs(tab_list)

Â  Â  Â  Â Â 

Â  Â  Â  Â  with tabs[0]:

Â  Â  Â  Â  Â  Â  st.subheader("ğŸ“Š Total - í†µí•© ê³¡ì„  ë° ìš´ì „ì  ë¶„ì„")

Â  Â  Â  Â  Â  Â  df_f = render_filters(df_r, m_r, "total")

Â  Â  Â  Â  Â  Â  models = df_f[m_r].unique().tolist() if m_r and not df_f.empty else []

Â  Â  Â  Â  Â  Â  with st.expander("ìš´ì „ì  ë¶„ì„ (Operating Point Analysis)"):

Â  Â  Â  Â  Â  Â  Â  Â  analysis_mode = st.radio("ë¶„ì„ ëª¨ë“œ", ["ê¸°ê³„", "ì†Œë°©"], key="analysis_mode", horizontal=True)

Â  Â  Â  Â  Â  Â  Â  Â  op_col1, op_col2 = st.columns(2)



Â  Â  Â  Â  Â  Â  Â  Â  # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜… ìµœì¢… ìˆ˜ì • ë¶€ë¶„ â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…

Â  Â  Â  Â  Â  Â  Â  Â  with op_col1:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  q_input_str = st.text_input("ëª©í‘œ ìœ ëŸ‰ (Q)", value="0.0")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  target_q = float(q_input_str)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except ValueError:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  target_q = 0.0

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("ìœ ëŸ‰ì— ìœ íš¨í•œ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", icon="âš ï¸")

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  with op_col2:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  h_input_str = st.text_input("ëª©í‘œ ì–‘ì • (H)", value="0.0")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  target_h = float(h_input_str)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except ValueError:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  target_h = 0.0

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("ì–‘ì •ì— ìœ íš¨í•œ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", icon="âš ï¸")

Â  Â  Â  Â  Â  Â  Â  Â  # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…



Â  Â  Â  Â  Â  Â  Â  Â  if analysis_mode == "ì†Œë°©": st.info("ì†Œë°© íŒí”„ ì„±ëŠ¥ ê¸°ì¤€ 3ì ì„ ìë™ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")

Â  Â  Â  Â  Â  Â  Â  Â  if st.button("ìš´ì „ì  ë¶„ì„ ì‹¤í–‰"):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not models: st.warning("ë¨¼ì € ë¶„ì„í•  ì‹œë¦¬ì¦ˆë‚˜ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner("ì„ íƒëœ ëª¨ë¸ë“¤ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if analysis_mode == "ì†Œë°©": op_results_df = analyze_fire_pump_point(df_r, models, target_q, target_h, m_r, q_col_total, h_col_total, k_col_total)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else: op_results_df = analyze_operating_point(df_r, models, target_q, target_h, m_r, q_col_total, h_col_total, k_col_total)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not op_results_df.empty: st.success(f"ì´ {len(op_results_df)}ê°œì˜ ëª¨ë¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤."); st.dataframe(op_results_df, use_container_width=True)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else: st.info("ìš”êµ¬ ì„±ëŠ¥ì„ ë§Œì¡±í•˜ëŠ” ëª¨ë¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

Â  Â  Â  Â  Â  Â  with st.expander("ì°¨íŠ¸ ë³´ì¡°ì„  ì¶”ê°€"):

Â  Â  Â  Â  Â  Â  Â  Â  g_col1, g_col2, g_col3 = st.columns(3)

Â  Â  Â  Â  Â  Â  Â  Â  with g_col1: h_guide_h, v_guide_h = st.number_input("Q-H ìˆ˜í‰ì„ ", value=0.0), st.number_input("Q-H ìˆ˜ì§ì„ ", value=0.0)

Â  Â  Â  Â  Â  Â  Â  Â  with g_col2: h_guide_k, v_guide_k = st.number_input("Q-kW ìˆ˜í‰ì„ ", value=0.0), st.number_input("Q-kW ìˆ˜ì§ì„ ", value=0.0)

Â  Â  Â  Â  Â  Â  Â  Â  with g_col3: h_guide_e, v_guide_e = st.number_input("Q-Eff ìˆ˜í‰ì„ ", value=0.0), st.number_input("Q-Eff ìˆ˜ì§ì„ ", value=0.0)

Â  Â  Â  Â  Â  Â  st.markdown("---")

Â  Â  Â  Â  Â  Â  ref_show = st.checkbox("Reference í‘œì‹œ", value=True); cat_show = st.checkbox("Catalog í‘œì‹œ"); dev_show = st.checkbox("Deviation í‘œì‹œ")

Â  Â  Â  Â  Â  Â  st.markdown(f"#### Q-H (ìœ ëŸ‰-{h_col_total})")

Â  Â  Â  Â  Â  Â  fig_h = go.Figure()

Â  Â  Â  Â  Â  Â  if ref_show and not df_f.empty: add_traces(fig_h, df_f, m_r, q_col_total, h_col_total, models, 'lines+markers'); add_bep_markers(fig_h, df_f, m_r, q_col_total, h_col_total, models)

Â  Â  Â  Â  Â  Â  if cat_show and not df_c.empty: add_traces(fig_h, df_c, m_c, q_c, h_c, models, 'lines+markers', line_style=dict(dash='dot'))

Â  Â  Â  Â  Â  Â  if dev_show and not df_d.empty: add_traces(fig_h, df_d, m_d, q_d, h_d, models, 'markers')

Â  Â  Â  Â  Â  Â  if 'target_q' in locals() and target_q > 0 and target_h > 0:

Â  Â  Â  Â  Â  Â  Â  Â  fig_h.add_trace(go.Scatter(x=[target_q], y=[target_h], mode='markers', marker=dict(symbol='cross', size=15, color='magenta'), name='ì •ê²© ìš´ì „ì '))

Â  Â  Â  Â  Â  Â  Â  Â  if analysis_mode == "ì†Œë°©":

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  churn_h_limit = 1.4 * target_h; fig_h.add_trace(go.Scatter(x=[0], y=[churn_h_limit], mode='markers', marker=dict(symbol='x', size=12, color='red'), name=f'ì²´ì ˆì  ìƒí•œ'))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  overload_q, overload_h_limit = 1.5 * target_q, 0.65 * target_h; fig_h.add_trace(go.Scatter(x=[overload_q], y=[overload_h_limit], mode='markers', marker=dict(symbol='diamond-open', size=12, color='blue'), name=f'ìµœëŒ€ì  í•˜í•œ'))

Â  Â  Â  Â  Â  Â  add_guide_lines(fig_h, h_guide_h, v_guide_h); render_chart(fig_h, "total_qh")

Â  Â  Â  Â  Â  Â  st.markdown("#### Q-kW (ìœ ëŸ‰-ì¶•ë™ë ¥)"); fig_k = go.Figure()

Â  Â  Â  Â  Â  Â  if ref_show and not df_f.empty: add_traces(fig_k, df_f, m_r, q_col_total, k_col_total, models, 'lines+markers')

Â  Â  Â  Â  Â  Â  if cat_show and not df_c.empty: add_traces(fig_k, df_c, m_c, q_c, k_c, models, 'lines+markers', line_style=dict(dash='dot'))

Â  Â  Â  Â  Â  Â  if dev_show and not df_d.empty: add_traces(fig_k, df_d, m_d, q_d, k_d, models, 'markers')

Â  Â  Â  Â  Â  Â  add_guide_lines(fig_k, h_guide_k, v_guide_k); render_chart(fig_k, "total_qk")

Â  Â  Â  Â  Â  Â  st.markdown("#### Q-Efficiency (ìœ ëŸ‰-íš¨ìœ¨)"); fig_e = go.Figure()

Â  Â  Â  Â  Â  Â  if ref_show and not df_f.empty: add_traces(fig_e, df_f, m_r, q_col_total, 'Efficiency', models, 'lines+markers'); add_bep_markers(fig_e, df_f, m_r, q_col_total, 'Efficiency', models)

Â  Â  Â  Â  Â  Â  if cat_show and not df_c.empty: add_traces(fig_e, df_c, m_c, q_c, 'Efficiency', models, 'lines+markers', line_style=dict(dash='dot'))

Â  Â  Â  Â  Â  Â  if dev_show and not df_d.empty: add_traces(fig_e, df_d, m_d, q_d, 'Efficiency', models, 'markers')

Â  Â  Â  Â  Â  Â  add_guide_lines(fig_e, h_guide_e, v_guide_e); render_chart(fig_e, "total_qe")



Â  Â  Â  Â  for idx, sheet_name in enumerate(["Reference", "Catalog", "Deviation"]):

Â  Â  Â  Â  Â  Â  with tabs[idx+1]:

Â  Â  Â  Â  Â  Â  Â  Â  st.subheader(f"ğŸ“Š {sheet_name} Data")

Â  Â  Â  Â  Â  Â  Â  Â  df, mcol, df_orig = (df_r, m_r, df_r_orig) if sheet_name == "Reference" else (df_c, m_c, df_c_orig) if sheet_name == "Catalog" else (df_d, m_d, df_d_orig)

Â  Â  Â  Â  Â  Â  Â  Â  if df.empty: st.info(f"'{sheet_name.lower()}' ì‹œíŠ¸ì˜ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); continue

Â  Â  Â  Â  Â  Â  Â  Â  q_col_tab = get_best_match_column(df_orig, ["í† ì¶œëŸ‰", "ìœ ëŸ‰"]); h_col_tab = get_best_match_column(df_orig, ["í† ì¶œì–‘ì •", "ì „ì–‘ì •"]); k_col_tab = get_best_match_column(df_orig, ["ì¶•ë™ë ¥"])

Â  Â  Â  Â  Â  Â  Â  Â  df_f_tab = render_filters(df, mcol, sheet_name)

Â  Â  Â  Â  Â  Â  Â  Â  models_tab = df_f_tab[mcol].unique().tolist() if not df_f_tab.empty else []

Â  Â  Â  Â  Â  Â  Â  Â  if not models_tab: st.info("ì°¨íŠ¸ë¥¼ ë³´ë ¤ë©´ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”."); continue

Â  Â  Â  Â  Â  Â  Â  Â  mode, style = ('markers', None) if sheet_name == "Deviation" else ('lines+markers', dict(dash='dot') if sheet_name == "Catalog" else None)

Â  Â  Â  Â  Â  Â  Â  Â  if h_col_tab: st.markdown(f"#### Q-H ({h_col_tab})"); fig1 = go.Figure(); add_traces(fig1, df_f_tab, mcol, q_col_tab, h_col_tab, models_tab, mode, line_style=style); render_chart(fig1, key=f"{sheet_name}_qh")

Â  Â  Â  Â  Â  Â  Â  Â  if k_col_tab in df_f_tab.columns: st.markdown("#### Q-kW (ì¶•ë™ë ¥)"); fig2 = go.Figure(); add_traces(fig2, df_f_tab, mcol, q_col_tab, k_col_tab, models_tab, mode, line_style=style); render_chart(fig2, key=f"{sheet_name}_qk")

Â  Â  Â  Â  Â  Â  Â  Â  if 'Efficiency' in df_f_tab.columns: st.markdown("#### Q-Efficiency (íš¨ìœ¨)"); fig3 = go.Figure(); add_traces(fig3, df_f_tab, mcol, q_col_tab, 'Efficiency', models_tab, mode, line_style=style); fig3.update_layout(yaxis_title="íš¨ìœ¨ (%)", yaxis=dict(range=[0, 100])); render_chart(fig3, key=f"{sheet_name}_qe")

Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("#### ë°ì´í„° í™•ì¸"); st.dataframe(df_f_tab, use_container_width=True)

Â  Â  Â  Â Â 

Â  Â  Â  Â  with tabs[4]:

Â  Â  Â  Â  Â  Â  st.subheader("ğŸ”¬ Reference Data í†µê³„ì  ìœ íš¨ì„± ê²€ì¦")

Â  Â  Â  Â  Â  Â  power_cols_exist = k_col_total and k_d

Â  Â  Â  Â  Â  Â  if not power_cols_exist: st.info("ì¶•ë™ë ¥ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” Referenceì™€ Deviation ì‹œíŠ¸ ì–‘ìª½ì— 'ì¶•ë™ë ¥' ê´€ë ¨ ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

Â  Â  Â  Â  Â  Â  if df_d_orig.empty or test_id_col_d is None: st.warning("ìœ íš¨ì„± ê²€ì¦ì„ ìœ„í•´ 'deviation data' ì‹œíŠ¸ì™€ 'ì‹œí—˜ë²ˆí˜¸' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("Deviation ë°ì´í„° í™•ì¸í•˜ê¸°"): st.dataframe(df_d_orig)

Â  Â  Â  Â  Â  Â  Â  Â  common_models = sorted(list(set(df_r[m_r].unique()) & set(df_d[m_d].unique())))

Â  Â  Â  Â  Â  Â  Â  Â  if not common_models: st.info("Referenceì™€ Deviation ë°ì´í„°ì— ê³µí†µìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")

Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  models_to_validate = st.multiselect("ê²€ì¦í•  ëª¨ë¸ ì„ íƒ", common_models, default=common_models[:1])

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.button("ğŸ“ˆ í†µê³„ ê²€ì¦ ì‹¤í–‰"):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner("í†µê³„ ë¶„ì„ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤..."):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  head_results = perform_validation_analysis(df_r, df_d, m_r, m_d, q_col_total, q_d, h_col_total, h_d, test_id_col_d, models_to_validate, "ì–‘ì •")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if power_cols_exist: power_results = perform_validation_analysis(df_r, df_d, m_r, m_d, q_col_total, q_d, k_col_total, k_d, test_id_col_d, models_to_validate, "ì¶•ë™ë ¥")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("í†µê³„ ë¶„ì„ ì™„ë£Œ!")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for model in models_to_validate:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("---"); st.markdown(f"### ëª¨ë¸: {model}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  col1, col2 = st.columns(2)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with col1:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("ğŸ“ˆ ì–‘ì •(Head) ìœ íš¨ì„± ê²€ì¦")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  display_validation_output(model, head_results, "ì–‘ì •", df_r, df_d, m_r, m_d, q_col_total, q_d, h_col_total, h_d, test_id_col_d)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with col2:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if power_cols_exist:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("âš¡ ì¶•ë™ë ¥(Power) ìœ íš¨ì„± ê²€ì¦")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  display_validation_output(model, power_results, "ì¶•ë™ë ¥", df_r, df_d, m_r, m_d, q_col_total, q_d, k_col_total, k_d, test_id_col_d)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("---"); st.header("ğŸ“Š í‘œì¤€ì„±ëŠ¥ ê³¡ì„  ì œì•ˆ (Reference vs. ì‹¤ì¸¡ í‰ê· )")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  fig_col1, fig_col2 = st.columns(2)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with fig_col1:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("Q-H Curve (ì–‘ì •)")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  fig_h_proposal = go.Figure()

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for model in models_to_validate:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if model in head_results and not head_results[model]['summary'].empty:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  summary_df = head_results[model]['summary']

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  summary_df['í‰ê· '] = pd.to_numeric(summary_df['í‰ê· '], errors='coerce')

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  fig_h_proposal.add_trace(go.Scatter(x=summary_df['ê²€ì¦ ìœ ëŸ‰(Q)'], y=summary_df['í‰ê· '], mode='lines+markers', name=f'{model} (ì œì•ˆ)'))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  model_r_df = df_r[df_r[m_r] == model].sort_values(q_col_total)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  fig_h_proposal.add_trace(go.Scatter(x=model_r_df[q_col_total], y=model_r_df[h_col_total], mode='lines', name=f'{model} (ê¸°ì¡´)', line=dict(dash='dot'), opacity=0.7))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.plotly_chart(fig_h_proposal, use_container_width=True)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with fig_col2:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if power_cols_exist:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("Q-kW Curve (ì¶•ë™ë ¥)")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  fig_k_proposal = go.Figure()

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for model in models_to_validate:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if model in power_results and not power_results[model]['summary'].empty:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  summary_df = power_results[model]['summary']

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  summary_df['í‰ê· '] = pd.to_numeric(summary_df['í‰ê· '], errors='coerce')

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  fig_k_proposal.add_trace(go.Scatter(x=summary_df['ê²€ì¦ ìœ ëŸ‰(Q)'], y=summary_df['í‰ê· '], mode='lines+markers', name=f'{model} (ì œì•ˆ)'))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  model_r_df = df_r[df_r[m_r] == model].sort_values(q_col_total)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  fig_k_proposal.add_trace(go.Scatter(x=model_r_df[q_col_total], y=model_r_df[k_col_total], mode='lines', name=f'{model} (ê¸°ì¡´)', line=dict(dash='dot'), opacity=0.7))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.plotly_chart(fig_k_proposal, use_container_width=True)



else:

Â  Â  st.info("ì‹œì‘í•˜ë ¤ë©´ Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
