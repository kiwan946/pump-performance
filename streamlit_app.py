import streamlit as st
import pandas as pd
import plotly.graph_objs as go
import numpy as np
from scipy.stats import t

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="Dooch XRL(F) ì„±ëŠ¥ ê³¡ì„  ë·°ì–´ v19.0", layout="wide")
st.title("ğŸ“Š Dooch XRL(F) ì„±ëŠ¥ ê³¡ì„  ë·°ì–´ v19.0")

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ---
SERIES_ORDER = ["XRF3", "XRF5", "XRF10", "XRF15", "XRF20", "XRF32", "XRF45", "XRF64", "XRF95", "XRF125", "XRF155", "XRF185", "XRF215", "XRF255"]

def get_best_match_column(df, names):
    if df is None or df.empty: return None
    for n in names:
        for col in df.columns:
            if n in col.strip():
                return col
    return None

def calculate_efficiency(df, q_col, h_col, k_col):
    if not all(col and col in df.columns for col in [q_col, h_col, k_col]): return df
    df_copy = df.copy()
    hydraulic_power = 0.163 * df_copy[q_col] * df_copy[h_col]
    shaft_power = df_copy[k_col]
    df_copy['Efficiency'] = np.where(shaft_power > 0, (hydraulic_power / shaft_power) * 100, 0)
    return df_copy

def load_sheet(uploaded_file, sheet_name):
    try:
        df = pd.read_excel(uploaded_file, sheet_name=sheet_name)
        df.columns = df.columns.str.strip()
        mcol = get_best_match_column(df, ["ëª¨ë¸ëª…", "ëª¨ë¸", "Model"])
        if not mcol: return None, pd.DataFrame()
        if 'Series' in df.columns: df = df.drop(columns=['Series'])
        df['Series'] = df[mcol].astype(str).str.extract(r"(XRF\d+)")
        df['Series'] = pd.Categorical(df['Series'], categories=SERIES_ORDER, ordered=True)
        df = df.sort_values('Series')
        return mcol, df
    except Exception:
        return None, pd.DataFrame()

def process_data(df, q_col, h_col, k_col):
    if df.empty: return df
    temp_df = df.copy()
    for col in [q_col, h_col, k_col]:
        if col in temp_df.columns:
            temp_df = temp_df.dropna(subset=[col])
            temp_df = temp_df[pd.to_numeric(temp_df[col], errors='coerce').notna()]
            temp_df[col] = pd.to_numeric(temp_df[col])
    return calculate_efficiency(temp_df, q_col, h_col, k_col)

# --- ë¶„ì„ ë° ì‹œê°í™” í•¨ìˆ˜ë“¤ ---
def analyze_operating_point(df, models, target_q, target_h, m_col, q_col, h_col, k_col):
    if target_q <= 0 or target_h <= 0: return pd.DataFrame()
    results = []
    for model in models:
        model_df = df[df[m_col] == model].sort_values(q_col)
        if len(model_df) < 2 or not (model_df[q_col].min() <= target_q <= model_df[q_col].max()): continue
        interp_h = np.interp(target_q, model_df[q_col], model_df[h_col])
        if interp_h >= target_h:
            interp_kw = np.interp(target_q, model_df[q_col], model_df[k_col]) if k_col and k_col in model_df.columns else np.nan
            interp_eff = np.interp(target_q, model_df[q_col], model_df['Efficiency']) if 'Efficiency' in model_df.columns else np.nan
            results.append({"ëª¨ë¸ëª…": model, "ìš”êµ¬ ìœ ëŸ‰": target_q, "ìš”êµ¬ ì–‘ì •": target_h, "ì˜ˆìƒ ì–‘ì •": f"{interp_h:.2f}", "ì˜ˆìƒ ë™ë ¥(kW)": f"{interp_kw:.2f}", "ì˜ˆìƒ íš¨ìœ¨(%)": f"{interp_eff:.2f}", "ì„ ì • ê°€ëŠ¥": "âœ…"})
    return pd.DataFrame(results)

def analyze_fire_pump_point(df, models, target_q, target_h, m_col, q_col, h_col, k_col):
    if target_q <= 0 or target_h <= 0: return pd.DataFrame()
    results = []
    for model in models:
        model_df = df[df[m_col] == model].sort_values(q_col)
        if len(model_df) < 2: continue
        interp_h_rated = np.interp(target_q, model_df[q_col], model_df[h_col], left=np.nan, right=np.nan)
        if np.isnan(interp_h_rated) or interp_h_rated < target_h: continue
        h_churn = model_df.iloc[0][h_col]
        cond1_ok = h_churn <= (1.40 * target_h)
        q_overload = 1.5 * target_q
        interp_h_overload = np.interp(q_overload, model_df[q_col], model_df[h_col], left=np.nan, right=np.nan)
        cond2_ok = (not np.isnan(interp_h_overload)) and (interp_h_overload >= (0.65 * target_h))
        if cond1_ok and cond2_ok:
            interp_kw = np.interp(target_q, model_df[q_col], model_df[k_col]) if k_col and k_col in model_df.columns else np.nan
            results.append({"ëª¨ë¸ëª…": model, "ì •ê²© ì˜ˆìƒ ì–‘ì •": f"{interp_h_rated:.2f}", "ì²´ì ˆ ì–‘ì • (â‰¤{1.4*target_h:.2f})": f"{h_churn:.2f}", "ìµœëŒ€ìš´ì „ ì–‘ì • (â‰¥{0.65*target_h:.2f})": f"{interp_h_overload:.2f}", "ì˜ˆìƒ ë™ë ¥(kW)": f"{interp_kw:.2f}", "ì„ ì • ê°€ëŠ¥": "âœ…"})
    return pd.DataFrame(results)

def render_filters(df, mcol, prefix):
    if df is None or df.empty or mcol is None or 'Series' not in df.columns:
        st.warning("í•„í„°ë§í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    series_opts = df['Series'].dropna().unique().tolist()
    default_series = [series_opts[0]] if series_opts else []
    mode = st.radio("ë¶„ë¥˜ ê¸°ì¤€", ["ì‹œë¦¬ì¦ˆë³„", "ëª¨ë¸ë³„"], key=f"{prefix}_mode", horizontal=True)
    if mode == "ì‹œë¦¬ì¦ˆë³„":
        sel = st.multiselect("ì‹œë¦¬ì¦ˆ ì„ íƒ", series_opts, default=default_series, key=f"{prefix}_series")
        df_f = df[df['Series'].isin(sel)] if sel else pd.DataFrame()
    else:
        model_opts = df[mcol].dropna().unique().tolist()
        default_model = [model_opts[0]] if model_opts else []
        sel = st.multiselect("ëª¨ë¸ ì„ íƒ", model_opts, default=default_model, key=f"{prefix}_models")
        df_f = df[df[mcol].isin(sel)] if sel else pd.DataFrame()
    return df_f

def add_traces(fig, df, mcol, xcol, ycol, models, mode, line_style=None, name_suffix=""):
    for m in models:
        sub = df[df[mcol] == m].sort_values(xcol)
        if sub.empty or ycol not in sub.columns: continue
        fig.add_trace(go.Scatter(x=sub[xcol], y=sub[ycol], mode=mode, name=m + name_suffix, line=line_style or {}))

def add_bep_markers(fig, df, mcol, qcol, ycol, models):
    for m in models:
        model_df = df[df[mcol] == m]
        if not model_df.empty and 'Efficiency' in model_df.columns and not model_df['Efficiency'].isnull().all():
            bep_row = model_df.loc[model_df['Efficiency'].idxmax()]
            fig.add_trace(go.Scatter(x=[bep_row[qcol]], y=[bep_row[ycol]], mode='markers', marker=dict(symbol='star', size=15, color='gold'), name=f'{m} BEP'))

def add_guide_lines(fig, h_line, v_line):
    if h_line is not None and h_line > 0:
        fig.add_shape(type="line", x0=0, x1=1, xref="paper", y0=h_line, y1=h_line, yref="y", line=dict(color="gray", dash="dash"))
    if v_line is not None and v_line > 0:
        fig.add_shape(type="line", x0=v_line, x1=v_line, xref="x", y0=0, y1=1, yref="paper", line=dict(color="gray", dash="dash"))

def render_chart(fig, key):
    fig.update_layout(dragmode='pan', xaxis=dict(fixedrange=False), yaxis=dict(fixedrange=False), legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1))
    st.plotly_chart(fig, use_container_width=True, config={'scrollZoom': True, 'displaylogo': False}, key=key)

# â˜…â˜…â˜… ì‹ ê·œ ê²€ì¦ ë¶„ì„ í•¨ìˆ˜ â˜…â˜…â˜…
def perform_validation_analysis(df_r, df_d, m_r, m_d, q_r, h_r, q_d, h_d, test_id_col, models_to_validate):
    results_summary = []
    
    for model in models_to_validate:
        model_r_df = df_r[df_r[m_r] == model].sort_values(by=q_r)
        model_d_df = df_d[df_d[m_d] == model]

        if model_r_df.empty or model_d_df.empty: continue
        
        # 1. Validation ìœ ëŸ‰ êµ¬ê°„ ì„ ì • (10 í¬ì¸íŠ¸)
        max_q = model_r_df[q_r].max()
        validation_q = np.linspace(0, max_q, 10)
        
        # Reference ë°ì´í„° ë³´ê°„
        ref_h = np.interp(validation_q, model_r_df[q_r], model_r_df[h_r])
        
        # 2. Deviation ë°ì´í„°ë¥¼ ì‹œí—˜ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ êµ¬ë¶„
        test_ids = model_d_df[test_id_col].unique()
        interpolated_h_samples = {q: [] for q in validation_q}
        
        # 3. ê° ì‹œí—˜ ë°ì´í„°ë³„ë¡œ ë³´ê°„
        for test_id in test_ids:
            test_df = model_d_df[model_d_df[test_id_col] == test_id].sort_values(by=q_d)
            if len(test_df) < 2: continue
            interp_h = np.interp(validation_q, test_df[q_d], test_df[h_d])
            for i, q in enumerate(validation_q):
                interpolated_h_samples[q].append(interp_h[i])
        
        # 4. ê° ìœ ëŸ‰ êµ¬ê°„ë³„ í†µê³„ ë¶„ì„ ë° ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
        for i, q in enumerate(validation_q):
            samples = np.array(interpolated_h_samples[q])
            n = len(samples)
            if n < 2:
                # ìƒ˜í”Œì´ ë¶€ì¡±í•˜ì—¬ í†µê³„ ê³„ì‚° ë¶ˆê°€
                results_summary.append({"ëª¨ë¸ëª…": model, "ê²€ì¦ ìœ ëŸ‰(Q)": q, "ê¸°ì¤€ ì–‘ì •(H)": ref_h[i], "ì‹œí—˜ íšŸìˆ˜(n)": n, "í‰ê· ": np.nan, "í‘œì¤€í¸ì°¨": np.nan, "95% CI í•˜í•œ": np.nan, "95% CI ìƒí•œ": np.nan, "ìœ íš¨ì„±": "íŒë‹¨ë¶ˆê°€"})
                continue
            
            mean_h = np.mean(samples)
            std_dev = np.std(samples, ddof=1) # ddof=1 for sample standard deviation
            std_err = std_dev / np.sqrt(n)
            
            # t-ë¶„í¬ë¥¼ ì‚¬ìš©í•œ ì‹ ë¢°êµ¬ê°„ ê³„ì‚° (ìƒ˜í”Œ ìˆ˜ê°€ ì ì„ ë•Œ ë” ì •í™•)
            confidence_level = 0.95
            alpha = 1 - confidence_level
            t_critical = t.ppf(1 - alpha/2, df=n-1)
            
            margin_of_error = t_critical * std_err
            ci_lower = mean_h - margin_of_error
            ci_upper = mean_h + margin_of_error
            
            # ê¸°ì¤€ ì–‘ì •ì´ ì‹ ë¢°êµ¬ê°„ ë‚´ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
            is_valid = "âœ… ìœ íš¨" if ci_lower <= ref_h[i] <= ci_upper else "âŒ ë²—ì–´ë‚¨"
            
            results_summary.append({
                "ëª¨ë¸ëª…": model, 
                "ê²€ì¦ ìœ ëŸ‰(Q)": f"{q:.2f}",
                "ê¸°ì¤€ ì–‘ì •(H)": f"{ref_h[i]:.2f}",
                "ì‹œí—˜ íšŸìˆ˜(n)": n,
                "í‰ê· ": f"{mean_h:.2f}",
                "í‘œì¤€í¸ì°¨": f"{std_dev:.2f}",
                "95% CI í•˜í•œ": f"{ci_lower:.2f}",
                "95% CI ìƒí•œ": f"{ci_upper:.2f}",
                "ìœ íš¨ì„±": is_valid
            })
            
    return pd.DataFrame(results_summary)


# --- ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§ ---

uploaded_file = st.file_uploader("Excel íŒŒì¼ ì—…ë¡œë“œ (.xlsx ë˜ëŠ” .xlsm)", type=["xlsx", "xlsm"])

if uploaded_file:
    # 1. ì‹œíŠ¸ë³„ ì›ë³¸ ë°ì´í„° ë¡œë“œ
    m_r, df_r_orig = load_sheet(uploaded_file, "reference data")
    m_c, df_c_orig = load_sheet(uploaded_file, "catalog data")
    m_d, df_d_orig = load_sheet(uploaded_file, "deviation data")
    
    if df_r_orig.empty:
        st.error("ì˜¤ë¥˜: 'reference data' ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ 'ëª¨ë¸ëª…' ê´€ë ¨ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        # 2. ì‚¬ì´ë“œë°” ì»¬ëŸ¼ ì„ íƒ UI (Total íƒ­ ë° ë¶„ì„ìš©)
        st.sidebar.title("âš™ï¸ ë¶„ì„ ì„¤ì •")
        st.sidebar.markdown("### Total íƒ­ & ìš´ì „ì  ë¶„ì„ ì»¬ëŸ¼ ì§€ì •")
        
        all_columns_r = df_r_orig.columns.tolist()
        def safe_get_index(items, value, default=0):
            try: return items.index(value)
            except (ValueError, TypeError): return default

        q_auto_r = get_best_match_column(df_r_orig, ["í† ì¶œëŸ‰", "ìœ ëŸ‰"])
        h_auto_r = get_best_match_column(df_r_orig, ["í† ì¶œì–‘ì •", "ì „ì–‘ì •"])
        k_auto_r = get_best_match_column(df_r_orig, ["ì¶•ë™ë ¥"])
        
        q_col_total = st.sidebar.selectbox("ìœ ëŸ‰ (Flow) ì»¬ëŸ¼", all_columns_r, index=safe_get_index(all_columns_r, q_auto_r))
        h_col_total = st.sidebar.selectbox("ì–‘ì • (Head) ì»¬ëŸ¼", all_columns_r, index=safe_get_index(all_columns_r, h_auto_r))
        k_col_total = st.sidebar.selectbox("ì¶•ë™ë ¥ (Power) ì»¬ëŸ¼", all_columns_r, index=safe_get_index(all_columns_r, k_auto_r))
        
        # ê° ì‹œíŠ¸ë³„ ì»¬ëŸ¼ëª…ì„ ë…ë¦½ì ìœ¼ë¡œ ê°ì§€
        q_c, h_c, k_c = (get_best_match_column(df_c_orig, ["í† ì¶œëŸ‰", "ìœ ëŸ‰"]), get_best_match_column(df_c_orig, ["í† ì¶œì–‘ì •", "ì „ì–‘ì •"]), get_best_match_column(df_c_orig, ["ì¶•ë™ë ¥"]))
        q_d, h_d, k_d = (get_best_match_column(df_d_orig, ["í† ì¶œëŸ‰", "ìœ ëŸ‰"]), get_best_match_column(df_d_orig, ["í† ì¶œì–‘ì •", "ì „ì–‘ì •"]), get_best_match_column(df_d_orig, ["ì¶•ë™ë ¥"]))
        # â˜…â˜…â˜… Validation íƒ­ì„ ìœ„í•œ ì‹œí—˜ë²ˆí˜¸ ì»¬ëŸ¼ ê°ì§€ â˜…â˜…â˜…
        test_id_col_d = get_best_match_column(df_d_orig, ["ì‹œí—˜ë²ˆí˜¸", "Test No", "Test ID"])


        # 3. ê° ë°ì´í„°ì— ë§ëŠ” ì»¬ëŸ¼ìœ¼ë¡œ ë°ì´í„° ì •ì œ ë° íš¨ìœ¨ ê³„ì‚°
        df_r = process_data(df_r_orig, q_col_total, h_col_total, k_col_total)
        df_c = process_data(df_c_orig, q_c, h_c, k_c)
        df_d = process_data(df_d_orig, q_d, h_d, k_d)
        
        # 4. íƒ­ ìƒì„± ë° í™”ë©´ í‘œì‹œ
        tab_list = ["Total", "Reference", "Catalog", "Deviation", "Validation"] # â˜…â˜…â˜… Validation íƒ­ ì¶”ê°€ â˜…â˜…â˜…
        tabs = st.tabs(tab_list)

        with tabs[0]: # Total íƒ­
            st.subheader("ğŸ“Š Total - í†µí•© ê³¡ì„  ë° ìš´ì „ì  ë¶„ì„")
            df_f = render_filters(df_r, m_r, "total")
            models = df_f[m_r].unique().tolist() if m_r and not df_f.empty else []

            with st.expander("ìš´ì „ì  ë¶„ì„ (Operating Point Analysis)"):
                analysis_mode = st.radio("ë¶„ì„ ëª¨ë“œ", ["ê¸°ê³„", "ì†Œë°©"], key="analysis_mode", horizontal=True)
                op_col1, op_col2 = st.columns(2)
                with op_col1: target_q = st.number_input("ëª©í‘œ ìœ ëŸ‰ (Q)", value=0.0, format="%.2f")
                with op_col2: target_h = st.number_input("ëª©í‘œ ì–‘ì • (H)", value=0.0, format="%.2f")
                if analysis_mode == "ì†Œë°©": st.info("ì†Œë°© íŒí”„ ì„±ëŠ¥ ê¸°ì¤€ 3ì ì„ ìë™ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
                if st.button("ìš´ì „ì  ë¶„ì„ ì‹¤í–‰"):
                    if not models: st.warning("ë¨¼ì € ë¶„ì„í•  ì‹œë¦¬ì¦ˆë‚˜ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    else:
                        with st.spinner("ì„ íƒëœ ëª¨ë¸ë“¤ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                            if analysis_mode == "ì†Œë°©": op_results_df = analyze_fire_pump_point(df_r, models, target_q, target_h, m_r, q_col_total, h_col_total, k_col_total)
                            else: op_results_df = analyze_operating_point(df_r, models, target_q, target_h, m_r, q_col_total, h_col_total, k_col_total)
                            if not op_results_df.empty: st.success(f"ì´ {len(op_results_df)}ê°œì˜ ëª¨ë¸ì´ ìš”êµ¬ ì„±ëŠ¥ì„ ë§Œì¡±í•©ë‹ˆë‹¤."); st.dataframe(op_results_df, use_container_width=True)
                            else: st.info("ìš”êµ¬ ì„±ëŠ¥ì„ ë§Œì¡±í•˜ëŠ” ëª¨ë¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

            with st.expander("ì°¨íŠ¸ ë³´ì¡°ì„  ì¶”ê°€"):
                g_col1, g_col2, g_col3 = st.columns(3)
                with g_col1: h_guide_h, v_guide_h = st.number_input("Q-H ìˆ˜í‰ì„ ", value=0.0), st.number_input("Q-H ìˆ˜ì§ì„ ", value=0.0)
                with g_col2: h_guide_k, v_guide_k = st.number_input("Q-kW ìˆ˜í‰ì„ ", value=0.0), st.number_input("Q-kW ìˆ˜ì§ì„ ", value=0.0)
                with g_col3: h_guide_e, v_guide_e = st.number_input("Q-Eff ìˆ˜í‰ì„ ", value=0.0), st.number_input("Q-Eff ìˆ˜ì§ì„ ", value=0.0)

            st.markdown("---")
            ref_show = st.checkbox("Reference í‘œì‹œ", value=True)
            cat_show = st.checkbox("Catalog í‘œì‹œ")
            dev_show = st.checkbox("Deviation í‘œì‹œ")

            st.markdown(f"#### Q-H (ìœ ëŸ‰-{h_col_total})")
            fig_h = go.Figure()
            if ref_show and not df_f.empty: add_traces(fig_h, df_f, m_r, q_col_total, h_col_total, models, 'lines+markers'); add_bep_markers(fig_h, df_f, m_r, q_col_total, h_col_total, models)
            if cat_show and not df_c.empty: add_traces(fig_h, df_c, m_c, q_c, h_c, models, 'lines+markers', line_style=dict(dash='dot'))
            if dev_show and not df_d.empty: add_traces(fig_h, df_d, m_d, q_d, h_d, models, 'markers')
            if 'target_q' in locals() and target_q > 0 and target_h > 0:
                fig_h.add_trace(go.Scatter(x=[target_q], y=[target_h], mode='markers', marker=dict(symbol='cross', size=15, color='magenta'), name='ì •ê²© ìš´ì „ì '))
                if analysis_mode == "ì†Œë°©":
                    churn_h_limit = 1.4 * target_h; fig_h.add_trace(go.Scatter(x=[0], y=[churn_h_limit], mode='markers', marker=dict(symbol='x', size=12, color='red'), name=f'ì²´ì ˆì  ìƒí•œ'))
                    overload_q, overload_h_limit = 1.5 * target_q, 0.65 * target_h; fig_h.add_trace(go.Scatter(x=[overload_q], y=[overload_h_limit], mode='markers', marker=dict(symbol='diamond-open', size=12, color='blue'), name=f'ìµœëŒ€ì  í•˜í•œ'))
            add_guide_lines(fig_h, h_guide_h, v_guide_h)
            render_chart(fig_h, "total_qh")

            st.markdown("#### Q-kW (ìœ ëŸ‰-ì¶•ë™ë ¥)")
            fig_k = go.Figure()
            if ref_show and not df_f.empty: add_traces(fig_k, df_f, m_r, q_col_total, k_col_total, models, 'lines+markers')
            if cat_show and not df_c.empty: add_traces(fig_k, df_c, m_c, q_c, k_c, models, 'lines+markers', line_style=dict(dash='dot'))
            if dev_show and not df_d.empty: add_traces(fig_k, df_d, m_d, q_d, k_d, models, 'markers')
            add_guide_lines(fig_k, h_guide_k, v_guide_k)
            render_chart(fig_k, "total_qk")
            
            st.markdown("#### Q-Efficiency (ìœ ëŸ‰-íš¨ìœ¨)")
            fig_e = go.Figure()
            if ref_show and not df_f.empty: add_traces(fig_e, df_f, m_r, q_col_total, 'Efficiency', models, 'lines+markers'); add_bep_markers(fig_e, df_f, m_r, q_col_total, 'Efficiency', models)
            if cat_show and not df_c.empty: add_traces(fig_e, df_c, m_c, q_c, 'Efficiency', models, 'lines+markers', line_style=dict(dash='dot'))
            if dev_show and not df_d.empty: add_traces(fig_e, df_d, m_d, q_d, 'Efficiency', models, 'markers')
            add_guide_lines(fig_e, h_guide_e, v_guide_e)
            render_chart(fig_e, "total_qe")

        for idx, sheet_name in enumerate(["Reference", "Catalog", "Deviation"]):
            with tabs[idx+1]:
                st.subheader(f"ğŸ“Š {sheet_name} Data")
                df, mcol, df_orig = (df_r, m_r, df_r_orig) if sheet_name == "Reference" else \
                                  (df_c, m_c, df_c_orig) if sheet_name == "Catalog" else \
                                  (df_d, m_d, df_d_orig)
                
                if df.empty:
                    st.info(f"'{sheet_name.lower()}' ì‹œíŠ¸ì˜ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    continue

                q_col_tab = get_best_match_column(df_orig, ["í† ì¶œëŸ‰", "ìœ ëŸ‰"])
                h_col_tab = get_best_match_column(df_orig, ["í† ì¶œì–‘ì •", "ì „ì–‘ì •"])
                k_col_tab = get_best_match_column(df_orig, ["ì¶•ë™ë ¥"])

                df_f_tab = render_filters(df, mcol, sheet_name)
                models_tab = df_f_tab[mcol].unique().tolist() if not df_f_tab.empty else []

                if not models_tab:
                    st.info("ì°¨íŠ¸ë¥¼ ë³´ë ¤ë©´ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    continue
                
                mode, style = ('markers', None) if sheet_name == "Deviation" else ('lines+markers', dict(dash='dot') if sheet_name == "Catalog" else None)
                
                if h_col_tab: st.markdown(f"#### Q-H ({h_col_tab})"); fig1 = go.Figure(); add_traces(fig1, df_f_tab, mcol, q_col_tab, h_col_tab, models_tab, mode, line_style=style); render_chart(fig1, key=f"{sheet_name}_qh")
                if k_col_tab in df_f_tab.columns: st.markdown("#### Q-kW (ì¶•ë™ë ¥)"); fig2 = go.Figure(); add_traces(fig2, df_f_tab, mcol, q_col_tab, k_col_tab, models_tab, mode, line_style=style); render_chart(fig2, key=f"{sheet_name}_qk")
                if 'Efficiency' in df_f_tab.columns: st.markdown("#### Q-Efficiency (íš¨ìœ¨)"); fig3 = go.Figure(); add_traces(fig3, df_f_tab, mcol, q_col_tab, 'Efficiency', models_tab, mode, line_style=style); fig3.update_layout(yaxis_title="íš¨ìœ¨ (%)", yaxis=dict(range=[0, 100])); render_chart(fig3, key=f"{sheet_name}_qe")
                st.markdown("#### ë°ì´í„° í™•ì¸"); st.dataframe(df_f_tab, use_container_width=True)
        
        # â˜…â˜…â˜… ì‹ ê·œ Validation íƒ­ ë¡œì§ â˜…â˜…â˜…
        with tabs[4]:
            st.subheader("ğŸ”¬ Reference Data í†µê³„ì  ìœ íš¨ì„± ê²€ì¦")
            
            if df_d.empty or test_id_col_d is None:
                st.warning("ìœ íš¨ì„± ê²€ì¦ì„ ìœ„í•´ 'deviation data' ì‹œíŠ¸ì™€ 'ì‹œí—˜ë²ˆí˜¸' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                common_models = sorted(list(set(df_r[m_r].unique()) & set(df_d[m_d].unique())))
                if not common_models:
                    st.info("Referenceì™€ Deviation ë°ì´í„°ì— ê³µí†µìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    models_to_validate = st.multiselect("ê²€ì¦í•  ëª¨ë¸ ì„ íƒ", common_models, default=common_models[:1])

                    if st.button("ğŸ“ˆ í†µê³„ ê²€ì¦ ì‹¤í–‰"):
                        if not models_to_validate:
                            st.warning("ê²€ì¦í•  ëª¨ë¸ì„ í•˜ë‚˜ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.")
                        else:
                            with st.spinner("í†µê³„ ë¶„ì„ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
                                validation_results = perform_validation_analysis(
                                    df_r, df_d, m_r, m_d, q_col_total, h_col_total, q_d, h_d, test_id_col_d, models_to_validate
                                )
                            
                            st.success("í†µê³„ ë¶„ì„ ì™„ë£Œ!")
                            st.markdown("#### ë¶„ì„ ê²°ê³¼ ìš”ì•½")
                            st.dataframe(validation_results, use_container_width=True)

                            st.markdown("---")
                            st.markdown("#### ëª¨ë¸ë³„ ìƒì„¸ ê²°ê³¼ ì‹œê°í™”")

                            for model in models_to_validate:
                                st.markdown(f"##### ëª¨ë¸: {model}")
                                model_results = validation_results[validation_results['ëª¨ë¸ëª…'] == model].copy()
                                if model_results.empty:
                                    st.info(f"{model}ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                    continue
                                
                                # ë¬¸ìì—´ì„ ìˆ«ìë¡œ ë³€í™˜
                                numeric_cols = ["ê²€ì¦ ìœ ëŸ‰(Q)", "ê¸°ì¤€ ì–‘ì •(H)", "95% CI í•˜í•œ", "95% CI ìƒí•œ"]
                                for col in numeric_cols:
                                    model_results[col] = pd.to_numeric(model_results[col], errors='coerce')
                                
                                fig = go.Figure()
                                
                                # 1. 95% ì‹ ë¢°êµ¬ê°„ (ìŒì˜)
                                fig.add_trace(go.Scatter(x=model_results['ê²€ì¦ ìœ ëŸ‰(Q)'], y=model_results['95% CI ìƒí•œ'], fill=None, mode='lines', line_color='rgba(0,100,80,0.2)', name='95% CI ìƒí•œ'))
                                fig.add_trace(go.Scatter(x=model_results['ê²€ì¦ ìœ ëŸ‰(Q)'], y=model_results['95% CI í•˜í•œ'], fill='tonexty', mode='lines', line_color='rgba(0,100,80,0.2)', name='95% CI í•˜í•œ'))
                                
                                # 2. ê°œë³„ ì‹œí—˜ ë°ì´í„° ê³¡ì„ 
                                model_d_df = df_d[df_d[m_d] == model]
                                test_ids = model_d_df[test_id_col_d].unique()
                                for test_id in test_ids:
                                    test_df = model_d_df[model_d_df[test_id_col_d] == test_id].sort_values(by=q_d)
                                    fig.add_trace(go.Scatter(x=test_df[q_d], y=test_df[h_d], mode='lines', line=dict(width=1, color='grey'), name=f'ì‹œí—˜ {test_id}', opacity=0.5, showlegend=False))
                                
                                # 3. Reference data ê³¡ì„ 
                                model_r_df = df_r[df_r[m_r] == model].sort_values(by=q_col_total)
                                fig.add_trace(go.Scatter(x=model_r_df[q_col_total], y=model_r_df[h_col_total], mode='lines+markers', line=dict(color='blue', width=3), name='Reference Curve'))
                                
                                # 4. ê²€ì¦ í¬ì¸íŠ¸ (ìœ íš¨/ë²—ì–´ë‚¨)
                                valid_points = model_results[model_results['ìœ íš¨ì„±'] == 'âœ… ìœ íš¨']
                                invalid_points = model_results[model_results['ìœ íš¨ì„±'] == 'âŒ ë²—ì–´ë‚¨']
                                fig.add_trace(go.Scatter(x=valid_points['ê²€ì¦ ìœ ëŸ‰(Q)'], y=valid_points['ê¸°ì¤€ ì–‘ì •(H)'], mode='markers', marker=dict(color='green', size=10, symbol='circle'), name='ìœ íš¨ í¬ì¸íŠ¸'))
                                fig.add_trace(go.Scatter(x=invalid_points['ê²€ì¦ ìœ ëŸ‰(Q)'], y=invalid_points['ê¸°ì¤€ ì–‘ì •(H)'], mode='markers', marker=dict(color='red', size=10, symbol='x'), name='ë²—ì–´ë‚¨ í¬ì¸íŠ¸'))
                                
                                fig.update_layout(
                                    title=f'{model} - Reference ë°ì´í„° ìœ íš¨ì„± ê²€ì¦',
                                    xaxis_title=f"ìœ ëŸ‰(Q) - {q_col_total}",
                                    yaxis_title=f"ì–‘ì •(H) - {h_col_total}",
                                    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
                                )
                                st.plotly_chart(fig, use_container_width=True)

else:
    st.info("ì‹œì‘í•˜ë ¤ë©´ Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
